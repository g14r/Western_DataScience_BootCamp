{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Linear Regression; Boston Housing Price\n",
    "\n",
    "You can find the video explaning this notebook on the resources/ Unit3 in the OWL website.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes! sklearn has lots of datasets!  \n",
    "from sklearn.datasets import load_boston\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not talked about numpy yet! Lets do it now:\n",
    "- Numpy is a Python package for scientific computing \n",
    "- It provides multidimensional array object\n",
    "- Many mathematical operations on vectors and matrixcies can be done using numpy; and it is fast (vectorized code)!\n",
    "- you can learn more about numpy here: https://numpy.org/doc/stable/user/whatisnumpy.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the housing dataset\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PTRATIO', 'B', 'LSTAT'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets make a dataframe!\n",
    "boston_df = pd.DataFrame(boston.data)\n",
    "\n",
    "# column names\n",
    "boston_df.columns = boston.feature_names\n",
    "print(boston_df.columns)\n",
    "\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     price\n",
       "0     24.0\n",
       "1     21.6\n",
       "2     34.7\n",
       "3     33.4\n",
       "4     36.2\n",
       "..     ...\n",
       "501   22.4\n",
       "502   20.6\n",
       "503   23.9\n",
       "504   22.0\n",
       "505   11.9\n",
       "\n",
       "[506 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df = pd.DataFrame(boston.target)\n",
    "\n",
    "target_df.columns = ['price']\n",
    "\n",
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Counts')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a17d852b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of prices (this is the target of our dataset)\n",
    "plt.hist(target_df['price'],bins=50)\n",
    "\n",
    "#label\n",
    "plt.xlabel('House Price')\n",
    "plt.ylabel('Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the best linear fit, aka we are using linear regression. As explained in details in Unit 3, the goal of linear regression is to calculate the best coefficients to minimize the residual sum of squared between the the actual target and the estimated target values. We can use Python's Scikit-Learn for this purpose!\n",
    "\n",
    "See this link for more info about Scikit-Learn linear regression module:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to take:\n",
    "\n",
    "- Create a LinearRegression *object* : lreg = LinearRegression()\n",
    "- Fit a linear model : lreg.fit(X,Y) --> We can see intercept and coefficient values\n",
    "- Predict Y using the linear model with the estimated coefficients : lreg.predict()\n",
    "- Check how good is our model/fit: lreg.score()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = target_df['price']\n",
    "X = boston_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lreg = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made the object and we assign True to normalize. Normalize is one of the parameters of this object, when it sets to True, X will be normalized.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model \n",
    "lreg.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.49110328036144"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the intercept \n",
    "lreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.07170557e-01,  4.63952195e-02,  2.08602395e-02,  2.68856140e+00,\n",
       "       -1.77957587e+01,  3.80475246e+00,  7.51061703e-04, -1.47575880e+00,\n",
       "        3.05655038e-01, -1.23293463e-02, -9.53463555e-01,  9.39251272e-03,\n",
       "       -5.25466633e-01])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the coefficints for each feature (we have 13 features and for each we will get a coefficient)\n",
    "lreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficient Estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.107171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.046395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.020860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>2.688561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-17.795759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>3.804752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.475759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.305655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.953464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.009393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.525467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features  Coefficient Estimate\n",
       "0      CRIM             -0.107171\n",
       "1        ZN              0.046395\n",
       "2     INDUS              0.020860\n",
       "3      CHAS              2.688561\n",
       "4       NOX            -17.795759\n",
       "5        RM              3.804752\n",
       "6       AGE              0.000751\n",
       "7       DIS             -1.475759\n",
       "8       RAD              0.305655\n",
       "9       TAX             -0.012329\n",
       "10  PTRATIO             -0.953464\n",
       "11        B              0.009393\n",
       "12    LSTAT             -0.525467"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a dataframe of features \n",
    "coeff_df = pd.DataFrame(boston_df.columns)\n",
    "coeff_df.columns = ['Features']\n",
    "\n",
    "# add a new column for the coefficients\n",
    "coeff_df[\"Coefficient Estimate\"] = lreg.coef_\n",
    "\n",
    "# Show\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember when we talked about the feature importance in Unit 2? Here we go! We can see some of these features are more important than the others! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How about doing some prediction? \n",
    "\n",
    "We can use the dataset we have; and partition it to test and train set. Using training data, the algorithm *learns* the coeffcients. Then we use the test data (the algorithm has never seen the test data during the training) to do predictions; and we can compare the predicted value with the actual one! \n",
    "\n",
    "- To split the data to train and test, we can use skit-learn as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, **options)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float, int, None, optional\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. By default, the value is set to 0.25.\n",
      "        The default will change in version 0.21. It will remain 0.25 only\n",
      "        if ``train_size`` is unspecified, otherwise it will complement\n",
      "        the specified ``train_size``.\n",
      "    \n",
      "    train_size : float, int, or None, default None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "    \n",
      "    shuffle : boolean, optional (default=True)\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like or None (default is None)\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.30)\n",
    "help(train_test_split)\n",
    "# we assign 30% of data for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our regression object\n",
    "lreg = LinearRegression()\n",
    "\n",
    "# Once again do a linear regression, except only on the training sets this time\n",
    "lreg.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.11932275 20.69717906 28.83455216 21.35147485 24.91300365 45.3162689\n",
      " 35.30491298 16.12160976 21.27601177 28.26490131 13.73152129 21.69604949\n",
      " 40.6276757  20.83789713 17.28512548 22.59904406 23.84036188 17.12180529\n",
      " 10.79147646 19.12051165 23.16298841 35.21243983 25.57491927 23.32932604\n",
      " 35.36851087 24.36782651 23.04957372 20.31092766 37.10992904 20.15824369\n",
      " 18.32620249 12.98587063 11.57135918 22.37407351 25.96445811 19.41371542\n",
      " 24.12578509 22.54525652 23.41857532 21.01393726 31.08677172 32.68094177\n",
      " 17.15069395 27.05360951 34.76426204 27.09277233 21.59281387 14.40396369\n",
      " 17.77537411 31.78420315 22.17618425 29.10643881 15.61871868 26.53253822\n",
      " 26.67262503 32.79980463 30.84762678 16.40008815 20.49060661 18.02913706\n",
      " 17.95203877 13.05896343 16.99392288 11.70869161 14.26725294 23.62470645\n",
      " 13.69652326 22.56883454  9.36920026 35.79295472  8.96436734 10.66098417\n",
      " 14.9729218  20.18652504 15.39262487 20.49944573 23.2094633  33.98850418\n",
      " 23.3158248  18.80745696 21.27442418 42.82295305 25.14150466 23.43163761\n",
      " 20.59388463 24.14643754 30.53887776 18.68801959 27.7538826  33.47648714\n",
      " 25.58708985 37.55523127 34.39474122 24.67196857 36.62445726 33.819833\n",
      " 22.43271648  2.83982414 25.5116207  21.12492971 24.31730295 21.39376683\n",
      "  7.94394152  9.37912584 29.77193565 35.07003077 20.71960505 34.55177307\n",
      " 22.37544429 27.87842369 17.00592355 19.4842374  28.18516145 19.00553148\n",
      " 24.05429299 16.08947489 27.73110926 39.07092369 24.40241755 11.67390332\n",
      " 39.2563974   6.4830474  20.14910141 36.80932636  3.01693334 26.69941612\n",
      " 42.5243238  29.7247876  18.28886525 11.53420625 25.89969704 19.73096216\n",
      " 19.28089355 22.66261103 21.12574543  6.57884403 27.55906459 25.29743031\n",
      " 12.7037811  21.77585448 29.7531331  28.54351239 30.53668939 -5.92332369\n",
      " 18.7278253   3.94915859 30.41765781 16.34744706 19.79410873 38.13209422\n",
      " 28.2816109  20.44107029]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = lreg.predict(X_test)\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Plots\n",
    "\n",
    "As mentioned in Unit 2, Lesson 4 plotting residulas is useful to realize how good our trained model works on the test set. As shown below, the residulas dont have any specific patter (which is a sign of having a good model). And, thye are wihin an acceptable range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Residual Plots')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a240a8e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot the testing data\n",
    "test = plt.scatter(Y_pred,(Y_test-Y_pred),c='b',alpha=0.5)\n",
    "\n",
    "# Plot a horizontal axis line at 0\n",
    "plt.hlines(y=0,xmin=-10,xmax=50)\n",
    "\n",
    "#Labels\n",
    "plt.title('Residual Plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.652122977613406\n"
     ]
    }
   ],
   "source": [
    "# MSE for test\n",
    "MSE = np.mean((Y_test - Y_pred) ** 2)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.235325417151767\n"
     ]
    }
   ],
   "source": [
    "# MSE for training\n",
    "MSE = np.mean((Y_train - lreg.predict(X_train)) ** 2)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
